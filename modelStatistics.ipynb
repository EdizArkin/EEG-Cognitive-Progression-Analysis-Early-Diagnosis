{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "6377602a",
            "metadata": {},
            "source": [
                "# Statistical Analysis & Model Evaluation\n",
                "\n",
                "**Purpose:**\n",
                "Perform rigorous statistical evaluation of machine learning models to validate findings for publication.\n",
                "\n",
                "**Steps:**\n",
                "1.  **Load Data:** Read `df_baseline_processed.csv` and `df_longitudinal_processed.csv`.\n",
                "2.  **Baseline Statistical Analysis:** Calculate 95% Confidence Intervals (Bootstrap) and McNemar's Tests for HC vs MCI diagnosis.\n",
                "3.  **Longitudinal Statistical Analysis:** Calculate 95% Confidence Intervals for prognosis prediction (Accuracy).\n",
                "4.  **Reporting:** Print statistical results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "2bc32398",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Imports\n",
                "import os\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "from xgboost import XGBClassifier\n",
                "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.naive_bayes import GaussianNB\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.model_selection import StratifiedKFold, cross_val_predict, LeaveOneOut\n",
                "from sklearn.metrics import accuracy_score, confusion_matrix\n",
                "from statsmodels.stats.contingency_tables import mcnemar\n",
                "\n",
                "# Set random seed\n",
                "np.random.seed(42)\n",
                "\n",
                "# Plot settings\n",
                "sns.set_theme(style='whitegrid')\n",
                "pd.set_option('display.max_columns', None)\n",
                "\n",
                "# Paths\n",
                "PROCESSED_PATH = \"data/processed/\"\n",
                "OUT_FIGS = \"report/figs/\"\n",
                "os.makedirs(OUT_FIGS, exist_ok=True)\n",
                "\n",
                "BASELINE_FILE = \"df_baseline_processed.csv\"\n",
                "LONGITUDINAL_FILE = \"df_longitudinal_processed.csv\"\n",
                "\n",
                "def save_and_show(fig, out_fp):\n",
                "    \"\"\"Save matplotlib figure with tight layout and show it.\"\"\"\n",
                "    fig.tight_layout()\n",
                "    fig.savefig(out_fp, bbox_inches='tight', dpi=300)\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "9655b9fc",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Statistical Helper Functions\n",
                "def bootstrap_ci(y_true, y_pred, n_bootstraps=1000):\n",
                "    \"\"\"Calculate 95% Confidence Interval using Bootstrap sampling.\"\"\"\n",
                "    y_true = np.array(y_true)\n",
                "    y_pred = np.array(y_pred)\n",
                "    n = len(y_true)\n",
                "    accuracy_scores = []\n",
                "    \n",
                "    for _ in range(n_bootstraps):\n",
                "        # Resample with replacement\n",
                "        indices = np.random.choice(n, n, replace=True)\n",
                "        if len(np.unique(y_true[indices])) < 2:\n",
                "            # Skip useless samples\n",
                "            continue\n",
                "        acc = accuracy_score(y_true[indices], y_pred[indices])\n",
                "        accuracy_scores.append(acc)\n",
                "    \n",
                "    mean_acc = np.mean(accuracy_scores)\n",
                "    ci_low = np.percentile(accuracy_scores, 2.5)\n",
                "    ci_high = np.percentile(accuracy_scores, 97.5)\n",
                "    \n",
                "    return mean_acc, ci_low, ci_high\n",
                "\n",
                "def mcnemar_test(y_true, y_pred1, y_pred2):\n",
                "    \"\"\"Perform McNemar's Test for pairwise classifier comparison.\"\"\"\n",
                "    y_true = np.array(y_true)\n",
                "    y_pred1 = np.array(y_pred1)\n",
                "    y_pred2 = np.array(y_pred2)\n",
                "    \n",
                "    correct1 = (y_pred1 == y_true)\n",
                "    correct2 = (y_pred2 == y_true)\n",
                "    \n",
                "    # Contingency Table\n",
                "    #          M2 Correct  M2 Wrong\n",
                "    # M1 Correct    a         b\n",
                "    # M1 Wrong      c         d\n",
                "    a = np.sum(correct1 & correct2)\n",
                "    b = np.sum(correct1 & ~correct2)\n",
                "    c = np.sum(~correct1 & correct2)\n",
                "    d = np.sum(~correct1 & ~correct2)\n",
                "    \n",
                "    table = [[a, b], [c, d]]\n",
                "    \n",
                "    # Exact McNemar test (binomial)\n",
                "    result = mcnemar(table, exact=True)\n",
                "    return result.pvalue"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "585c8151",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading Processed Data...\n",
                        "Baseline Shape: (82, 572)\n",
                        "Longitudinal Shape: (47, 1799)\n"
                    ]
                }
            ],
            "source": [
                "# Load Data\n",
                "print(\"Loading Processed Data...\")\n",
                "df_baseline = pd.read_csv(os.path.join(PROCESSED_PATH, BASELINE_FILE))\n",
                "df_longitudinal = pd.read_csv(os.path.join(PROCESSED_PATH, LONGITUDINAL_FILE))\n",
                "\n",
                "print(f\"Baseline Shape: {df_baseline.shape}\")\n",
                "print(f\"Longitudinal Shape: {df_longitudinal.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "21f3b822",
            "metadata": {},
            "source": [
                "# 1. Baseline Diagnosis - Statistical Analysis\n",
                "\n",
                "Comparing algorithms (LR, RF, DT, SVM, NB, XGBoost) using 5-Fold Stratified CV.\n",
                "**New:** Calculating 95% Confidence Intervals and McNemar's p-values."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "a4f8d429",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Available columns in Baseline: ['CVT_LPP_C3', 'CVT_LPP_C4', 'CVT_LPP_Cz', 'CVT_LPP_F3', 'CVT_LPP_F4', 'CVT_LPP_F7', 'CVT_LPP_F8', 'CVT_LPP_Fp1', 'CVT_LPP_Fp2', 'CVT_LPP_Fz', 'CVT_LPP_O1', 'CVT_LPP_O2', 'CVT_LPP_P3', 'CVT_LPP_P4', 'CVT_LPP_POz', 'CVT_LPP_Pz', 'CVT_LPP_T3', 'CVT_LPP_T4', 'CVT_LPP_T5', 'CVT_LPP_T6', 'CVT_LPPmaxLoc_C3', 'CVT_LPPmaxLoc_C4', 'CVT_LPPmaxLoc_Cz', 'CVT_LPPmaxLoc_F3', 'CVT_LPPmaxLoc_F4', 'CVT_LPPmaxLoc_F7', 'CVT_LPPmaxLoc_F8', 'CVT_LPPmaxLoc_Fp1', 'CVT_LPPmaxLoc_Fp2', 'CVT_LPPmaxLoc_Fz', 'CVT_LPPmaxLoc_O1', 'CVT_LPPmaxLoc_O2', 'CVT_LPPmaxLoc_P3', 'CVT_LPPmaxLoc_P4', 'CVT_LPPmaxLoc_POz', 'CVT_LPPmaxLoc_Pz', 'CVT_LPPmaxLoc_T3', 'CVT_LPPmaxLoc_T4', 'CVT_LPPmaxLoc_T5', 'CVT_LPPmaxLoc_T6', 'CVT_N1minLoc_C3', 'CVT_N1minLoc_C4', 'CVT_N1minLoc_Cz', 'CVT_N1minLoc_F3', 'CVT_N1minLoc_F4', 'CVT_N1minLoc_F7', 'CVT_N1minLoc_F8', 'CVT_N1minLoc_Fp1', 'CVT_N1minLoc_Fp2', 'CVT_N1minLoc_Fz', 'CVT_N1minLoc_O1', 'CVT_N1minLoc_O2', 'CVT_N1minLoc_P3', 'CVT_N1minLoc_P4', 'CVT_N1minLoc_POz', 'CVT_N1minLoc_Pz', 'CVT_N1minLoc_T3', 'CVT_N1minLoc_T4', 'CVT_N1minLoc_T5', 'CVT_N1minLoc_T6', 'CVT_N1minPeakLoc_C3', 'CVT_N1minPeakLoc_C4', 'CVT_N1minPeakLoc_Cz', 'CVT_N1minPeakLoc_F3', 'CVT_N1minPeakLoc_F4', 'CVT_N1minPeakLoc_F7', 'CVT_N1minPeakLoc_F8', 'CVT_N1minPeakLoc_Fp1', 'CVT_N1minPeakLoc_Fp2', 'CVT_N1minPeakLoc_Fz', 'CVT_N1minPeakLoc_O1', 'CVT_N1minPeakLoc_O2', 'CVT_N1minPeakLoc_P3', 'CVT_N1minPeakLoc_P4', 'CVT_N1minPeakLoc_POz', 'CVT_N1minPeakLoc_Pz', 'CVT_N1minPeakLoc_T3', 'CVT_N1minPeakLoc_T4', 'CVT_N1minPeakLoc_T5', 'CVT_N1minPeakLoc_T6', 'CVT_N1minPeak_C3', 'CVT_N1minPeak_C4', 'CVT_N1minPeak_Cz', 'CVT_N1minPeak_F3', 'CVT_N1minPeak_F4', 'CVT_N1minPeak_F7', 'CVT_N1minPeak_F8', 'CVT_N1minPeak_Fp1', 'CVT_N1minPeak_Fp2', 'CVT_N1minPeak_Fz', 'CVT_N1minPeak_O1', 'CVT_N1minPeak_O2', 'CVT_N1minPeak_P3', 'CVT_N1minPeak_P4', 'CVT_N1minPeak_POz', 'CVT_N1minPeak_Pz', 'CVT_N1minPeak_T3', 'CVT_N1minPeak_T4', 'CVT_N1minPeak_T5', 'CVT_N1minPeak_T6', 'CVT_P1avg_C3', 'CVT_P1avg_C4', 'CVT_P1avg_Cz', 'CVT_P1avg_F3', 'CVT_P1avg_F4', 'CVT_P1avg_F7', 'CVT_P1avg_F8', 'CVT_P1avg_Fp1', 'CVT_P1avg_Fp2', 'CVT_P1avg_Fz', 'CVT_P1avg_O1', 'CVT_P1avg_O2', 'CVT_P1avg_P3', 'CVT_P1avg_P4', 'CVT_P1avg_POz', 'CVT_P1avg_Pz', 'CVT_P1avg_T3', 'CVT_P1avg_T4', 'CVT_P1avg_T5', 'CVT_P1avg_T6', 'CVT_P1maxLoc_C3', 'CVT_P1maxLoc_C4', 'CVT_P1maxLoc_Cz', 'CVT_P1maxLoc_F3', 'CVT_P1maxLoc_F4', 'CVT_P1maxLoc_F7', 'CVT_P1maxLoc_F8', 'CVT_P1maxLoc_Fp1', 'CVT_P1maxLoc_Fp2', 'CVT_P1maxLoc_Fz', 'CVT_P1maxLoc_O1', 'CVT_P1maxLoc_O2', 'CVT_P1maxLoc_P3', 'CVT_P1maxLoc_P4', 'CVT_P1maxLoc_POz', 'CVT_P1maxLoc_Pz', 'CVT_P1maxLoc_T3', 'CVT_P1maxLoc_T4', 'CVT_P1maxLoc_T5', 'CVT_P1maxLoc_T6', 'CVT_P1maxPeakLoc_C3', 'CVT_P1maxPeakLoc_C4', 'CVT_P1maxPeakLoc_Cz', 'CVT_P1maxPeakLoc_F3', 'CVT_P1maxPeakLoc_F4', 'CVT_P1maxPeakLoc_F7', 'CVT_P1maxPeakLoc_F8', 'CVT_P1maxPeakLoc_Fp1', 'CVT_P1maxPeakLoc_Fp2', 'CVT_P1maxPeakLoc_Fz', 'CVT_P1maxPeakLoc_O1', 'CVT_P1maxPeakLoc_O2', 'CVT_P1maxPeakLoc_P3', 'CVT_P1maxPeakLoc_P4', 'CVT_P1maxPeakLoc_POz', 'CVT_P1maxPeakLoc_Pz', 'CVT_P1maxPeakLoc_T3', 'CVT_P1maxPeakLoc_T4', 'CVT_P1maxPeakLoc_T5', 'CVT_P1maxPeakLoc_T6', 'CVT_P1max_C3', 'CVT_P1max_C4', 'CVT_P1max_Cz', 'CVT_P1max_F3', 'CVT_P1max_F4', 'CVT_P1max_F7', 'CVT_P1max_F8', 'CVT_P1max_Fp1', 'CVT_P1max_Fp2', 'CVT_P1max_Fz', 'CVT_P1max_O1', 'CVT_P1max_O2', 'CVT_P1max_P3', 'CVT_P1max_P4', 'CVT_P1max_POz', 'CVT_P1max_Pz', 'CVT_P1max_T3', 'CVT_P1max_T4', 'CVT_P1max_T5', 'CVT_P1max_T6', 'CVT_P400avg_C3', 'CVT_P400avg_C4', 'CVT_P400avg_Cz', 'CVT_P400avg_F3', 'CVT_P400avg_F4', 'CVT_P400avg_F7', 'CVT_P400avg_F8', 'CVT_P400avg_Fp1', 'CVT_P400avg_Fp2', 'CVT_P400avg_Fz', 'CVT_P400avg_O1', 'CVT_P400avg_O2', 'CVT_P400avg_P3', 'CVT_P400avg_P4', 'CVT_P400avg_POz', 'CVT_P400avg_Pz', 'CVT_P400avg_T3', 'CVT_P400avg_T4', 'CVT_P400avg_T5', 'CVT_P400avg_T6', 'CVT_P400maxLoc_C3', 'CVT_P400maxLoc_C4', 'CVT_P400maxLoc_Cz', 'CVT_P400maxLoc_F3', 'CVT_P400maxLoc_F4', 'CVT_P400maxLoc_F7', 'CVT_P400maxLoc_F8', 'CVT_P400maxLoc_Fp1', 'CVT_P400maxLoc_Fp2', 'CVT_P400maxLoc_Fz', 'CVT_P400maxLoc_O1', 'CVT_P400maxLoc_O2', 'CVT_P400maxLoc_P3', 'CVT_P400maxLoc_P4', 'CVT_P400maxLoc_POz', 'CVT_P400maxLoc_Pz', 'CVT_P400maxLoc_T3', 'CVT_P400maxLoc_T4', 'CVT_P400maxLoc_T5', 'CVT_P400maxLoc_T6', 'CVT_P400maxPeakLoc_C3', 'CVT_P400maxPeakLoc_C4', 'CVT_P400maxPeakLoc_Cz', 'CVT_P400maxPeakLoc_F3', 'CVT_P400maxPeakLoc_F4', 'CVT_P400maxPeakLoc_F7', 'CVT_P400maxPeakLoc_F8', 'CVT_P400maxPeakLoc_Fp1', 'CVT_P400maxPeakLoc_Fp2', 'CVT_P400maxPeakLoc_Fz', 'CVT_P400maxPeakLoc_O1', 'CVT_P400maxPeakLoc_O2', 'CVT_P400maxPeakLoc_P3', 'CVT_P400maxPeakLoc_P4', 'CVT_P400maxPeakLoc_POz', 'CVT_P400maxPeakLoc_Pz', 'CVT_P400maxPeakLoc_T3', 'CVT_P400maxPeakLoc_T4', 'CVT_P400maxPeakLoc_T5', 'CVT_P400maxPeakLoc_T6', 'CVT_P400maxPeak_C3', 'CVT_P400maxPeak_C4', 'CVT_P400maxPeak_Cz', 'CVT_P400maxPeak_F3', 'CVT_P400maxPeak_F4', 'CVT_P400maxPeak_F7', 'CVT_P400maxPeak_F8', 'CVT_P400maxPeak_Fp1', 'CVT_P400maxPeak_Fp2', 'CVT_P400maxPeak_Fz', 'CVT_P400maxPeak_O1', 'CVT_P400maxPeak_O2', 'CVT_P400maxPeak_P3', 'CVT_P400maxPeak_P4', 'CVT_P400maxPeak_POz', 'CVT_P400maxPeak_Pz', 'CVT_P400maxPeak_T3', 'CVT_P400maxPeak_T4', 'CVT_P400maxPeak_T5', 'CVT_P400maxPeak_T6', 'CVT_P400max_C3', 'CVT_P400max_C4', 'CVT_P400max_Cz', 'CVT_P400max_F3', 'CVT_P400max_F4', 'CVT_P400max_F7', 'CVT_P400max_F8', 'CVT_P400max_Fp1', 'CVT_P400max_Fp2', 'CVT_P400max_Fz', 'CVT_P400max_O1', 'CVT_P400max_O2', 'CVT_P400max_P3', 'CVT_P400max_P4', 'CVT_P400max_POz', 'CVT_P400max_Pz', 'CVT_P400max_T3', 'CVT_P400max_T4', 'CVT_P400max_T5', 'CVT_P400max_T6', 'CVT_SNR_C3', 'CVT_SNR_C4', 'CVT_SNR_Cz', 'CVT_SNR_F3', 'CVT_SNR_F4', 'CVT_SNR_F7', 'CVT_SNR_F8', 'CVT_SNR_Fp1', 'CVT_SNR_Fp2', 'CVT_SNR_Fz', 'CVT_SNR_O1', 'CVT_SNR_O2', 'CVT_SNR_P3', 'CVT_SNR_P4', 'CVT_SNR_POz', 'CVT_SNR_Pz', 'CVT_SNR_T3', 'CVT_SNR_T4', 'CVT_SNR_T5', 'CVT_SNR_T6', 'Genotype', 'IAF', 'MMSE_delta', 'PDDM95', 'PERF_3CVT_PC', 'PERF_3CVT_RT', 'PERF_SIR_PC', 'PERF_SIR_RT', 'SIR_LPP3755_C3', 'SIR_LPP3755_C4', 'SIR_LPP3755_Cz', 'SIR_LPP3755_F3', 'SIR_LPP3755_F4', 'SIR_LPP3755_F7', 'SIR_LPP3755_F8', 'SIR_LPP3755_Fp1', 'SIR_LPP3755_Fp2', 'SIR_LPP3755_Fz', 'SIR_LPP3755_O1', 'SIR_LPP3755_O2', 'SIR_LPP3755_P3', 'SIR_LPP3755_P4', 'SIR_LPP3755_POz', 'SIR_LPP3755_Pz', 'SIR_LPP3755_T3', 'SIR_LPP3755_T4', 'SIR_LPP3755_T5', 'SIR_LPP3755_T6', 'SIR_LPP46_C3', 'SIR_LPP46_C4', 'SIR_LPP46_Cz', 'SIR_LPP46_F3', 'SIR_LPP46_F4', 'SIR_LPP46_F7', 'SIR_LPP46_F8', 'SIR_LPP46_Fp1', 'SIR_LPP46_Fp2', 'SIR_LPP46_Fz', 'SIR_LPP46_O1', 'SIR_LPP46_O2', 'SIR_LPP46_P3', 'SIR_LPP46_P4', 'SIR_LPP46_POz', 'SIR_LPP46_Pz', 'SIR_LPP46_T3', 'SIR_LPP46_T4', 'SIR_LPP46_T5', 'SIR_LPP46_T6', 'SIR_LPP_C3', 'SIR_LPP_C4', 'SIR_LPP_Cz', 'SIR_LPP_F3', 'SIR_LPP_F4', 'SIR_LPP_F7', 'SIR_LPP_F8', 'SIR_LPP_Fp1', 'SIR_LPP_Fp2', 'SIR_LPP_Fz', 'SIR_LPP_O1', 'SIR_LPP_O2', 'SIR_LPP_P3', 'SIR_LPP_P4', 'SIR_LPP_POz', 'SIR_LPP_Pz', 'SIR_LPP_T3', 'SIR_LPP_T4', 'SIR_LPP_T5', 'SIR_LPP_T6', 'SIR_LPPcluster_C3', 'SIR_LPPcluster_C4', 'SIR_LPPcluster_Cz', 'SIR_LPPcluster_F3', 'SIR_LPPcluster_F4', 'SIR_LPPcluster_F7', 'SIR_LPPcluster_F8', 'SIR_LPPcluster_Fp1', 'SIR_LPPcluster_Fp2', 'SIR_LPPcluster_Fz', 'SIR_LPPcluster_O1', 'SIR_LPPcluster_O2', 'SIR_LPPcluster_P3', 'SIR_LPPcluster_P4', 'SIR_LPPcluster_POz', 'SIR_LPPcluster_Pz', 'SIR_LPPcluster_T3', 'SIR_LPPcluster_T4', 'SIR_LPPcluster_T5', 'SIR_LPPcluster_T6', 'SIR_LPPmax_C3', 'SIR_LPPmax_C4', 'SIR_LPPmax_Cz', 'SIR_LPPmax_F3', 'SIR_LPPmax_F4', 'SIR_LPPmax_F7', 'SIR_LPPmax_F8', 'SIR_LPPmax_Fp1', 'SIR_LPPmax_Fp2', 'SIR_LPPmax_Fz', 'SIR_LPPmax_O1', 'SIR_LPPmax_O2', 'SIR_LPPmax_P3', 'SIR_LPPmax_P4', 'SIR_LPPmax_POz', 'SIR_LPPmax_Pz', 'SIR_LPPmax_T3', 'SIR_LPPmax_T4', 'SIR_LPPmax_T5', 'SIR_LPPmax_T6', 'SIR_P200_maxPeakLoc_C3', 'SIR_P200_maxPeakLoc_C4', 'SIR_P200_maxPeakLoc_Cz', 'SIR_P200_maxPeakLoc_F3', 'SIR_P200_maxPeakLoc_F4', 'SIR_P200_maxPeakLoc_F7', 'SIR_P200_maxPeakLoc_F8', 'SIR_P200_maxPeakLoc_Fp1', 'SIR_P200_maxPeakLoc_Fp2', 'SIR_P200_maxPeakLoc_Fz', 'SIR_P200_maxPeakLoc_O1', 'SIR_P200_maxPeakLoc_O2', 'SIR_P200_maxPeakLoc_P3', 'SIR_P200_maxPeakLoc_P4', 'SIR_P200_maxPeakLoc_POz', 'SIR_P200_maxPeakLoc_Pz', 'SIR_P200_maxPeakLoc_T3', 'SIR_P200_maxPeakLoc_T4', 'SIR_P200_maxPeakLoc_T5', 'SIR_P200_maxPeakLoc_T6', 'SIR_P200_maxPeak_C3', 'SIR_P200_maxPeak_C4', 'SIR_P200_maxPeak_Cz', 'SIR_P200_maxPeak_F3', 'SIR_P200_maxPeak_F4', 'SIR_P200_maxPeak_F7', 'SIR_P200_maxPeak_F8', 'SIR_P200_maxPeak_Fp1', 'SIR_P200_maxPeak_Fp2', 'SIR_P200_maxPeak_Fz', 'SIR_P200_maxPeak_O1', 'SIR_P200_maxPeak_O2', 'SIR_P200_maxPeak_P3', 'SIR_P200_maxPeak_P4', 'SIR_P200_maxPeak_POz', 'SIR_P200_maxPeak_Pz', 'SIR_P200_maxPeak_T3', 'SIR_P200_maxPeak_T4', 'SIR_P200_maxPeak_T5', 'SIR_P200_maxPeak_T6', 'SIR_P200avg_C3', 'SIR_P200avg_C4', 'SIR_P200avg_Cz', 'SIR_P200avg_F3', 'SIR_P200avg_F4', 'SIR_P200avg_F7', 'SIR_P200avg_F8', 'SIR_P200avg_Fp1', 'SIR_P200avg_Fp2', 'SIR_P200avg_Fz', 'SIR_P200avg_O1', 'SIR_P200avg_O2', 'SIR_P200avg_P3', 'SIR_P200avg_P4', 'SIR_P200avg_POz', 'SIR_P200avg_Pz', 'SIR_P200avg_T3', 'SIR_P200avg_T4', 'SIR_P200avg_T5', 'SIR_P200avg_T6', 'SIR_P200maxLoc_C3', 'SIR_P200maxLoc_C4', 'SIR_P200maxLoc_Cz', 'SIR_P200maxLoc_F3', 'SIR_P200maxLoc_F4', 'SIR_P200maxLoc_F7', 'SIR_P200maxLoc_F8', 'SIR_P200maxLoc_Fp1', 'SIR_P200maxLoc_Fp2', 'SIR_P200maxLoc_Fz', 'SIR_P200maxLoc_O1', 'SIR_P200maxLoc_O2', 'SIR_P200maxLoc_P3', 'SIR_P200maxLoc_P4', 'SIR_P200maxLoc_POz', 'SIR_P200maxLoc_Pz', 'SIR_P200maxLoc_T3', 'SIR_P200maxLoc_T4', 'SIR_P200maxLoc_T5', 'SIR_P200maxLoc_T6', 'SIR_P200max_C3', 'SIR_P200max_C4', 'SIR_P200max_Cz', 'SIR_P200max_F3', 'SIR_P200max_F4', 'SIR_P200max_F7', 'SIR_P200max_F8', 'SIR_P200max_Fp1', 'SIR_P200max_Fp2', 'SIR_P200max_Fz', 'SIR_P200max_O1', 'SIR_P200max_O2', 'SIR_P200max_P3', 'SIR_P200max_P4', 'SIR_P200max_POz', 'SIR_P200max_Pz', 'SIR_P200max_T3', 'SIR_P200max_T4', 'SIR_P200max_T5', 'SIR_P200max_T6', 'SIR_SNR_C3', 'SIR_SNR_C4', 'SIR_SNR_Cz', 'SIR_SNR_F3', 'SIR_SNR_F4', 'SIR_SNR_F7', 'SIR_SNR_F8', 'SIR_SNR_Fp1', 'SIR_SNR_Fp2', 'SIR_SNR_Fz', 'SIR_SNR_O1', 'SIR_SNR_O2', 'SIR_SNR_P3', 'SIR_SNR_P4', 'SIR_SNR_POz', 'SIR_SNR_Pz', 'SIR_SNR_T3', 'SIR_SNR_T4', 'SIR_SNR_T5', 'SIR_SNR_T6', 'Testbed_V2', 'V2_Conservative_Amnestic', 'V2_Conservative_NP_Classification', 'V2_Custom_Amnestic', 'V2_Custom_NP_Classification', 'V2_Original_NP_Classification', 'V2_Peterson_Amnestic', 'V2_Peterson_Classification', 'V3_Conservative_Amnestic', 'V3_Conservative_Classification', 'V3_Custom_Amnestic', 'V3_Custom_NP_Classification_', 'V3_Original_NP_Classification', 'V3_Peterson_Amnestic', 'V3_Peterson_NP_Classification', 'cluster_1_3CVTslow_NonTarget', 'cluster_1_3CVTslow_Target', 'cluster_1_SIRslow_NonTarget', 'cluster_1_SIRslow_Target', 'cluster_2_3CVTslow_Target', 'cluster_2_SIRslow_NonTarget', 'cluster_2_SIRslow_Target', 'cluster_3_SIRslow_NonTarget', 'cluster_4_SIRslow_NonTarget', 'count', 'delta_1_Original', 'delta_2_Custom', 'delta_3_Custom_Amnestic', 'delta_4_Conserv', 'delta_5_Conserv_Amnestic', 'delta_6_Peterson', 'delta_7_Peterson_Amnestic', 'ref', 'study_prefix', 'task', 'Age', 'Age_MGH', 'Gender', 'Gender_MGH', 'Iter', 'MMSE', 'Race', 'Site_01', 'Diagnosis_base']\n",
                        "\n",
                        "Running Baseline Statistical Benchmark...\n",
                        "\n",
                        "Model                | Mean Acc   | 95% CI              \n",
                        "-------------------------------------------------------\n",
                        "Logistic Regression  | 0.7958     | [0.7073, 0.8902]\n",
                        "Decision Tree        | 0.8311     | [0.7439, 0.9024]\n",
                        "Random Forest        | 0.8176     | [0.7317, 0.9024]\n",
                        "SVM                  | 0.8029     | [0.7192, 0.8780]\n",
                        "Naive Bayes          | 0.7815     | [0.6948, 0.8659]\n",
                        "KNN                  | 0.7942     | [0.6951, 0.8780]\n",
                        "XGBoost              | 0.8792     | [0.8049, 0.9390]\n",
                        "\n",
                        "PAIRWISE McNEMAR TEST (vs XGBoost)\n",
                        "--------------------------------------------------\n",
                        "XGBoost vs Logistic Regression  | p=0.0654 | Sig: No\n",
                        "XGBoost vs Decision Tree        | p=0.3438 | Sig: No\n",
                        "XGBoost vs Random Forest        | p=0.2266 | Sig: No\n",
                        "XGBoost vs SVM                  | p=0.1460 | Sig: No\n",
                        "XGBoost vs Naive Bayes          | p=0.0386 | Sig: Yes\n",
                        "XGBoost vs KNN                  | p=0.1435 | Sig: No\n"
                    ]
                }
            ],
            "source": [
                "# Prepare Data (Same as model.ipynb)\n",
                "print(f'Available columns in Baseline: {df_baseline.columns.tolist()}')\n",
                "target_col = 'Diagnosis_base'\n",
                "if target_col not in df_baseline.columns:\n",
                "    target_col = 'Diagnosis'\n",
                "\n",
                "# Drop clear leakage columns\n",
                "X_base = df_baseline.drop(columns=[target_col, 'Condition', 'Condition_clean'], errors='ignore')\n",
                "y_base = df_baseline[target_col]\n",
                "\n",
                "# Variance Threshold\n",
                "feature_names = X_base.columns\n",
                "selector = VarianceThreshold(threshold=0) \n",
                "X_base = selector.fit_transform(X_base)\n",
                "feature_names = feature_names[selector.get_support()]\n",
                "\n",
                "# Model Definitions\n",
                "models_baseline = {\n",
                "    'Logistic Regression': Pipeline([\n",
                "        ('selector', SelectKBest(score_func=f_classif, k=10)),\n",
                "        ('clf', LogisticRegression(max_iter=200, class_weight='balanced'))\n",
                "    ]),\n",
                "    'Decision Tree': Pipeline([\n",
                "        ('clf', DecisionTreeClassifier(max_depth=5, class_weight='balanced', random_state=42))\n",
                "    ]),\n",
                "    'Random Forest': Pipeline([\n",
                "        ('clf', RandomForestClassifier(n_estimators=150, max_depth=6, random_state=42))\n",
                "    ]),\n",
                "    'SVM': Pipeline([\n",
                "        ('selector', SelectKBest(score_func=f_classif, k=10)),\n",
                "        ('clf', SVC(kernel='linear', class_weight='balanced', random_state=42))\n",
                "    ]),\n",
                "    'Naive Bayes': Pipeline([\n",
                "        ('selector', SelectKBest(score_func=f_classif, k=10)),\n",
                "        ('clf', GaussianNB())\n",
                "    ]),\n",
                "    'KNN': Pipeline([\n",
                "        ('selector', SelectKBest(score_func=f_classif, k=10)),\n",
                "        ('clf', KNeighborsClassifier(n_neighbors=5))\n",
                "    ]),\n",
                "    'XGBoost': XGBClassifier(\n",
                "        n_estimators=300,\n",
                "        max_depth=4,\n",
                "        learning_rate=0.05,\n",
                "        subsample=0.9,\n",
                "        colsample_bytree=0.9,\n",
                "        eval_metric='logloss',\n",
                "        random_state=42\n",
                "    )\n",
                "}\n",
                "\n",
                "# Statistical Evaluation Loop\n",
                "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
                "\n",
                "print(\"\\nRunning Baseline Statistical Benchmark...\\n\")\n",
                "results_base = {}\n",
                "baseline_preds = {}\n",
                "\n",
                "print(f\"{'Model':<20} | {'Mean Acc':<10} | {'95% CI':<20}\")\n",
                "print(\"-\" * 55)\n",
                "\n",
                "for name, model in models_baseline.items():\n",
                "    y_pred = cross_val_predict(model, X_base, y_base, cv=cv)\n",
                "    baseline_preds[name] = y_pred\n",
                "    \n",
                "    # Bootstrap CI\n",
                "    mean_acc, ci_low, ci_high = bootstrap_ci(y_base, y_pred)\n",
                "    results_base[name] = mean_acc\n",
                "    \n",
                "    print(f\"{name:<20} | {mean_acc:.4f}     | [{ci_low:.4f}, {ci_high:.4f}]\")\n",
                "\n",
                "# McNemar's Test (vs XGBoost)\n",
                "print(\"\\nPAIRWISE McNEMAR TEST (vs XGBoost)\")\n",
                "print(\"-\" * 50)\n",
                "xgb_pred = baseline_preds['XGBoost']\n",
                "\n",
                "for name in baseline_preds:\n",
                "    if name == 'XGBoost': continue\n",
                "    p_val = mcnemar_test(y_base, xgb_pred, baseline_preds[name])\n",
                "    sig = \"Yes\" if p_val < 0.05 else \"No\"\n",
                "    print(f\"XGBoost vs {name:<20} | p={p_val:.4f} | Sig: {sig}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "73c38789",
            "metadata": {},
            "source": [
                "# 2. Final Baseline Model (Analysis)\n",
                "\n",
                "XGBoost Confusion Matrix & Detailed Metrics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "264c2f15",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Baseline XGBoost Accuracy (CV): 0.8780\n"
                    ]
                }
            ],
            "source": [
                "y_pred_base = baseline_preds['XGBoost']\n",
                "acc_base = accuracy_score(y_base, y_pred_base)\n",
                "print(f\"Baseline XGBoost Accuracy (CV): {acc_base:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "63f79b13",
            "metadata": {},
            "source": [
                "# 3. Longitudinal Prognosis - Statistical Analysis\n",
                "\n",
                "Applying Bootstrap CI to LOOCV results for small dataset validation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "cc12ee9a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model                | Mean Acc   | 95% CI              \n",
                        "-------------------------------------------------------\n",
                        "Logistic Regression  | 0.5329     | [0.4043, 0.6809]\n",
                        "Decision Tree        | 0.4873     | [0.3404, 0.6383]\n",
                        "Random Forest        | 0.3591     | [0.2340, 0.4894]\n",
                        "SVM                  | 0.5955     | [0.4681, 0.7234]\n",
                        "Naive Bayes          | 0.3621     | [0.2340, 0.5106]\n",
                        "KNN                  | 0.6151     | [0.4681, 0.7452]\n",
                        "XGBoost              | 0.5107     | [0.3830, 0.6596]\n"
                    ]
                }
            ],
            "source": [
                "# Prepare Longitudinal Data (Same as model.ipynb)\n",
                "target_long = 'MCI_progression_V1' if 'MCI_progression_V1' in df_longitudinal.columns else 'MCI_progression'\n",
                "df_long_model = df_longitudinal.dropna(subset=[target_long]).copy()\n",
                "# Binary target\n",
                "df_long_model['target_binary'] = df_long_model[target_long].apply(lambda x: 0 if x < 0 else 1)\n",
                "y_long = df_long_model['target_binary']\n",
                "\n",
                "# Drop leakage\n",
                "leakage_keywords = ['_V2', '_Diff', 'progression', 'target', 'Diagnosis_V2', 'MCI_score_V2', 'diff']\n",
                "features_to_drop = [c for c in df_long_model.columns if any(k.lower() in c.lower() for k in leakage_keywords)]\n",
                "X_long = df_long_model.drop(columns=features_to_drop, errors='ignore')\n",
                "\n",
                "# Variance Threshold\n",
                "selector = VarianceThreshold(threshold=0) \n",
                "X_long = selector.fit_transform(X_long)\n",
                "\n",
                "# Model List\n",
                "models_longitudinal = {\n",
                "    'Logistic Regression': Pipeline([\n",
                "        ('selector', SelectKBest(score_func=f_classif, k=10)),\n",
                "        ('clf', LogisticRegression(max_iter=200, class_weight='balanced'))\n",
                "    ]),\n",
                "    'Decision Tree': Pipeline([\n",
                "        ('clf', DecisionTreeClassifier(max_depth=5, class_weight='balanced', random_state=42))\n",
                "    ]),\n",
                "    'Random Forest': Pipeline([\n",
                "        ('clf', RandomForestClassifier(n_estimators=150, max_depth=6, random_state=42))\n",
                "    ]),\n",
                "    'SVM': Pipeline([\n",
                "        ('selector', SelectKBest(score_func=f_classif, k=10)),\n",
                "        ('clf', SVC(kernel='linear', class_weight='balanced', random_state=42))\n",
                "    ]),\n",
                "    'Naive Bayes': Pipeline([\n",
                "        ('selector', SelectKBest(score_func=f_classif, k=10)),\n",
                "        ('clf', GaussianNB())\n",
                "    ]),\n",
                "    'KNN': Pipeline([\n",
                "        ('selector', SelectKBest(score_func=f_classif, k=10)),\n",
                "        ('clf', KNeighborsClassifier(n_neighbors=5))\n",
                "    ]),\n",
                "    'XGBoost': XGBClassifier(\n",
                "        n_estimators=300,\n",
                "        max_depth=4,\n",
                "        learning_rate=0.05,\n",
                "        subsample=0.9,\n",
                "        colsample_bytree=0.9,\n",
                "        eval_metric='logloss',\n",
                "        random_state=42\n",
                "    )\n",
                "}\n",
                "\n",
                "# Evaluation Loop (LOOCV + Bootstrap)\n",
                "cv_loo = LeaveOneOut()\n",
                "results_long = {}\n",
                "\n",
                "print(f\"{'Model':<20} | {'Mean Acc':<10} | {'95% CI':<20}\")\n",
                "print(\"-\" * 55)\n",
                "\n",
                "for name, model in models_longitudinal.items():\n",
                "    # Use cross_val_predict for LOOCV to get concise predictions vector\n",
                "    y_pred = cross_val_predict(model, X_long, y_long, cv=cv_loo)\n",
                "    \n",
                "    mean_acc, ci_low, ci_high = bootstrap_ci(y_long, y_pred)\n",
                "    results_long[name] = mean_acc\n",
                "    \n",
                "    print(f\"{name:<20} | {mean_acc:.4f}     | [{ci_low:.4f}, {ci_high:.4f}]\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 4. Final Longitudinal Model (KNN)\n",
                "\n",
                "Detailed breakdown of the best performing longitudinal model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Final KNN Accuracy: 0.6197 (95% CI: 0.4894 - 0.7660)\n"
                    ]
                }
            ],
            "source": [
                "# Re-train best model for plotting context\n",
                "model_long = Pipeline([\n",
                "    ('selector', SelectKBest(score_func=f_classif, k=10)),\n",
                "    ('knn', KNeighborsClassifier(n_neighbors=5))\n",
                "])\n",
                "\n",
                "y_pred_long = cross_val_predict(model_long, X_long, y_long, cv=cv_loo)\n",
                "mean_acc, ci_low, ci_high = bootstrap_ci(y_long, y_pred_long)\n",
                "\n",
                "print(f\"Final KNN Accuracy: {mean_acc:.4f} (95% CI: {ci_low:.4f} - {ci_high:.4f})\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
